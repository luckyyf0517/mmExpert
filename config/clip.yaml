# Cleaned configuration for radar data with adaptive patch sizing
log_dir: 'log/'
strategy: 'ddp'

data_cfg:
  target: src.data_interface.HumanDInterface
  params:
    cfg:
      # Dataset splits
      train_split: ['dataset/HumanML3D/_split/train.json']
      train_ratio: [1.0]
      val_split: ['dataset/HumanML3D/_split/val.json']
      val_ratio: [1.0]
      test_split: ['dataset/HumanML3D/_split/test.json']
      test_ratio: [1.0]

      # Radar data configuration
      opt:
        max_motion_length: 496      # Full padded length
        min_motion_len: 96          # Minimum motion length
        max_text_len: 20            # Maximum text caption length
        unit_length: 16             # Unit length for processing
        log_norm: true              # Apply log normalization
        radar_views: 'all'          # Radar views to use: 'all', 'doppler_only', 'range_only', 'azimuth_only'

        # Disabled parameters (kept for compatibility but not used)
        udoppler_postfix: ''  # Legacy parameter
        random_rotate: false
        random_scale: false
        thresholding: false

      batch_size: 64                # Batch size for training
      num_workers: 1                # Number of data loading workers
      sample_ratio: 1

model_cfg:
  target: src.model.clip.CLIP
  params:
    # Training parameters
    max_epochs: 200
    learning_rate: 1.0e-04
    temperature: 0.07              # CLIP temperature parameter

    # Encoder configurations
    encoder_configs:
      radar:
        embed_dim: 256      # Feature embedding dimension
        dropout: 0.1        # Dropout rate

      text:
        model_name: 'sentence-transformers/paraphrase-MiniLM-L6-v2'
        embed_dim: 256
        max_length: 77
        pooling_strategy: 'pooler'
        freeze_backbone: false
